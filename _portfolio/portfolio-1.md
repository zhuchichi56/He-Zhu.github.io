---
title: "NUS SummerWorkShop"
excerpt: "The poster of HAWKEYE<br/><img src='/images/NUS.png' style='zoom:50%'>"
collection: portfolio
---

We utilized **PyTorch, Flask, Raspberry Pi, YOLO5, and OpenCV** to train and develop a system capable of detecting and tracking human behavior. This system can gather data on pedestrian movement using cameras and sensors, communicate with a backend through the network, and provide real-time feedback.

We collected and built a dataset of 10 scenarios (consisting of about 21,000 frames) depicting **pedestrian falls, impacts, and other related events** in various locations. This dataset was used to train and test a model for temporal action behavior.

We classified pedestrians into seven points (head, limbs, torso), adapted and refined the **T-GCN model** to predict and classify action behavior, and achieved outstanding results as demonstrated in related papers. Our work was recognized for its innovation by Professor NUS.



